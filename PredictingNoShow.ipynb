{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Import necessary packages and elements\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import math\n",
    "import sqlalchemy\n",
    "import scipy as sp\n",
    "from scipy import stats\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import MetaData, Table, Column, Integer, Float, String\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import f_regression, SelectKBest, chi2, RFE, f_classif\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score,f1_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to database, truncate table, read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Connect to database\n",
    "engine = create_engine(\"(masked)/OASIS_Sandbox?driver=SQL+Server+Native+Client+11.0?(masked)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Rebuild the table to train the model\n",
    "building_table = (\"\"\"\n",
    "drop table if exists #tempnoshow\n",
    "drop table if exists #prevbilling\n",
    "drop table if exists #appttypes\n",
    "drop table if exists #apptkeys\n",
    "drop table if exists #diagnoses\n",
    "drop table if exists 'oasis_sandbox.cat.gbusch_NoShowFeatures'\n",
    "\n",
    "SELECT \n",
    "DP.[MRN Alpha]\n",
    "\n",
    ",dd.Date\n",
    ",case when [Disease Type] not in ('Unmapped','No Value') then [Disease Type] else [Disease Subgroup] end 'Disease Type'\n",
    "into #diagnoses\n",
    "from oasis.mart.v_FactEnc FE\n",
    "inner join oasis.mart.v_DimPatient DP on DP.[Pat Key] = fe.[Pat Key]\n",
    "inner join oasis.mart.v_DImDate dd on dd.[Date Key] = fe.[Discharge Date Key] and dd.Date >= dateadd(day,-910,getdate())\n",
    "inner join oasis.mart.v_DimDiagnosis dd1 on dd1.[Dx Key] = fe.[Mapped Dx Key]\n",
    "where [Disease Type] not in ('Unmapped','No Value') or [Disease Subgroup] <> 'Unmapped'\n",
    "\n",
    "select \n",
    "1 as 'visits'\n",
    ",f.[Appt Cancel Lead Days]\n",
    ",ds.[Appt Status Name]\n",
    ",case when [Appt Status Name] in ('Completed','Arrived') then 1 \n",
    "when [Appt Status Name] = 'No Show' then 0 \n",
    "when ([Appt Cancel Lead Days] <= 2 and [Appt Cancel Lead Days] >= 0) then 0  end as 'Completed Appt'\n",
    ",case when ds.[Appt Status Name] = 'No Show' then 1 \n",
    "when ([Appt Cancel Lead Days] <= 2 and [Appt Cancel Lead Days] >= 0) then 1 \n",
    "--when ds.[Appt Status Name] = 'Scheduled' then 1 \n",
    "when ds.[Appt Status Name] in ('Completed','Arrived') then 0 end as 'No Show Appts'\n",
    ",da.[Contact Serial Number]\n",
    ",f.[Appt Date Time]\n",
    ",datediff(day,[Appt Made Date],dd.Date) as 'leadtime'\n",
    ",dag.Age\n",
    ",case when dp.Sex = 'Male' then 1 else 0 end as 'ismale'\n",
    ",dat.[Appt Type Class]\n",
    ",case when db.[SCCA Contract] is not null then (case when db.[SCCA Contract] like 'Premera%' and db.[Payor Class] not like 'Medi%' then 1 else 0 end) end\n",
    "\n",
    " as 'TopPayor'\n",
    ",case when db.[Payor Class] is not null then\n",
    "(case when db.[Payor Subclass] like 'Regence%' or \n",
    "db.[Payor Subclass] like 'United%' or \n",
    "db.[Payor Subclass] like 'BCBS%' or \n",
    "db.[Payor Subclass] like 'Aetna%' or \n",
    "db.[Payor Subclass] like 'BDCT%' and db.[Payor Class] not like 'Medi%' then 1 else 0 end)  end as 'Next5Payors'\n",
    ",case when db.[Payor Class] is not null then (case when db.[Payor Class] like 'Medicaid%' then 1 else 0 end) end as 'Medicaid'\n",
    ",case when db.[Payor Class] is not null then (case when db.[Payor Class] like 'Medicare%' then 1 else 0 end) end as 'Medicare'\n",
    ",case when db.[Payor Class] is not null then (case when db.[Payor Class] like 'Self Pay' then 1 else 0 end) end as 'SelfPay'\n",
    "\n",
    ",dd.Date as 'Appt Date'\n",
    ",row_number() over (partition by f.[Pat Key],dd.[Date Key] order by f.[Appt Date Time] asc) as 'RowNum'\n",
    ",dp.[MRN Alpha] 'MRN'\n",
    ", case when [Employment status] in ('On Active Military Duty','Employed Full-time','Self-employed','Employed Part-time') then 1 else 0 end as 'employed'\n",
    ",dsl.[Service Line Key]\n",
    ",z.Latitude 'PatLat'\n",
    ",z.Longitude 'PatLong'\n",
    ",zc.Latitude 'SiteLat'\n",
    ",zc.Longitude 'SiteLong'\n",
    ",case when dat.[Rpt Grp Six] = 'New' then 1 else 0 end as 'newappt'\n",
    ",case when dat.[Rpt Grp Six] = 'Return' then 1 else 0 end as 'retappt'\n",
    ", case when [Phone Number] in ('Unknown','No Match') then 1 else 0 end as 'nophonenumber'\n",
    ",case when race in ('Unknown','Other','No Match') then 1 else 0 end as 'otherrace'\n",
    ",case when race = 'Multiracial' then 1 else 0 end as 'multirace'\n",
    ", case when race = 'Black or African American' then 1 else 0 end as 'africanamericanrace'\n",
    ", case when race = 'American Indian or Alaska Native' then 1 else 0 end as 'americanindianrace'\n",
    ", case when race = 'Hispanic' then 1 else 0 end as 'hispanicrace'\n",
    ", case when race = 'White' then 1 else 0 end as 'whiterace'\n",
    ", case when race = 'Native Hawaiian or Other Pacific Islander' then 1 else 0 end 'pacislanderrace'\n",
    ", case when race = 'Asian' then 1 else 0 end as 'asianrace'\n",
    ",f.[Pat Key]\n",
    ",dd.[Date Key]\n",
    ",dpp.[Prov Type Subcategory]\n",
    ",f.[Sched Appt Length]\n",
    ",dat.[Appt Type Key]\n",
    ",ddiag.[Disease Type]\n",
    ",ddiag.[Disease Subgroup]\n",
    ",dsl.[Service Line]\n",
    ",[Prov Name]\n",
    "\n",
    "into #tempnoshow\n",
    "FROM oasis.mart.v_FactAppt f \n",
    "inner join oasis.mart.v_DimApptStatus ds on ds.[Appt Status Key] = f.[Appt Status Key]\n",
    "inner join oasis.mart.v_DimAppointment da on da.[Appt Key] = f.[Appt Key]\n",
    "inner join oasis.mart.v_DimSite dss on dss.[Site Key] = f.[Site Key]\n",
    "inner join oasis.mart.v_DimDate dd on dd.[Date Key] = f.[Appt Date Key]\n",
    "inner join oasis.mart.v_DimPatient dp on dp.[Pat Key] = f.[Pat Key]\n",
    "left join oasis.mart.v_FactEncAll fe on fe.[Enc Key] = f.[Enc Key]\n",
    "left join oasis.mart.v_DimPayorBenPlan db on db.[Payor Ben Plan Key] = fe.[Payor Ben Plan Key]\n",
    "inner join oasis.mart.v_DimAge dag on dag.[Age Key] = f.[Pat Appt Age Key]\n",
    "INNER JOIN OASIS_Sandbox.dbo.ZipCode z ON dp.[Zip Code] = z.ZipCode\n",
    "INNER JOIN OASIS_Sandbox.dbo.ZipCode zc on zc.[Site] = dss.[Site]\n",
    "INNER JOIN oasis.mart.V_DimServiceLine DSL on DSL.[Service Line Key] = f.[Service Line Key]\n",
    "inner join oasis.mart.v_DimApptType dat on dat.[Appt Type Key] = f.[Appt Type Key]\n",
    "inner join oasis.mart.v_DimProvider dpp on dpp.[Prov Key] = f.[Primary Prov Key]\n",
    "inner join oasis.mart.v_FactPatient FP on FP.[Pat Key] = f.[Pat Key]\n",
    "inner join oasis.mart.v_DimDiagnosis ddiag on ddiag.[Dx Key] = fp.[Last Enc Mapped Dx Key]\n",
    "\n",
    "where 1=1\n",
    "and ([Appt Cancel Lead Days] < 3 or ds.[Appt Status Name] in ('Arrived','Completed','No Show','Scheduled'))\n",
    "and not (dd.Date <= dateadd(day,-7,getdate()) and ds.[Appt Status Name] = 'Scheduled')\n",
    "and f.[Death Date] is null\n",
    "and [Appt Type Name] not like '%phone%'\n",
    "and dss.[Site] = 'SLU'\n",
    "and not dat.[Appt Type name] ='PERIPHERAL DRAW UW 3RD FLR LAB'\n",
    "and not dat.[Appt Type Name] = 'SCCA LAB'\n",
    "and not dat.[Appt Type Name] = 'PAIN PROTOCOL'\n",
    "and not dat.[Appt Type Name] = 'FOOD SAFETY CLASS'\n",
    "and not dat.[Appt Type Name] = 'SOCIAL WORKER VISIT-GO'\n",
    "and not dat.[Appt Type Name] = 'PAIN-MODIFIED PROTOCOL'\n",
    "and not dat.[Appt Type Name] = 'SCCA PHYSICAL THERAPY RET 60'\n",
    "and not dat.[Appt Type Name] like '%peds %'\n",
    "and not dat.[Appt Type Name] like '%pediatric %'\n",
    "and not dat.[Appt Type Name] like '%PUMP DISCONNECT%'\n",
    "--and not dsl.[Service Line] = 'Transplant'\n",
    "\n",
    "\n",
    "-- First temp table to identify low % appt types by service line\n",
    "SELECT dat.[Appt Type Name],count(*) 'count'\n",
    ",sum(case when ds.[Appt Status Name] = 'No Show' then 1 when ([Appt Cancel Lead Days] <= 2 and [Appt Cancel Lead Days] >= 0) \n",
    "then 1 when ds.[Appt Status Name] in ('Completed','Arrived') then 0 end) as 'No Show Appts1'\n",
    ",dat.[Appt Type Key]\n",
    ",dsl.[Service Line Key]\n",
    "into #appttypes\n",
    " FROM oasis.mart.v_FactAppt fa\n",
    "inner join OASIS.mart.v_DimApptType dat on dat.[Appt Type Key] = fa.[Appt Type Key]\n",
    "inner join oasis.mart.v_DimApptStatus ds on ds.[Appt Status Key] = fa.[Appt Status Key]\n",
    "inner join oasis.mart.v_DimDate dd on dd.[Date Key] = fa.[Appt Date Key] and date between dateadd(day,-730,getdate()) and dateadd(day,30,GETDATE())\n",
    "inner join oasis.mart.v_DimServiceLine dsl on dsl.[Service Line Key] = fa.[Service Line Key]\n",
    "\n",
    "group by dat.[Appt Type Name]\n",
    ",dat.[Appt Type Key]\n",
    ",dsl.[Service Line Key]\n",
    "\n",
    "\n",
    "select *\n",
    "\n",
    ",left(cast(ISNULL([No Show Appts1] * 100,0) as decimal) / cast(([Count] * 100) as decimal),4) 'Percent'\n",
    "into #apptkeys\n",
    " from #appttypes\n",
    "\n",
    "where ([Count] >20\n",
    "or cast(left(cast(ISNULL([No Show Appts1] * 100,0) as decimal) / cast(([Count] * 100) as decimal),4) as decimal) <.60)\n",
    "and not cast(left(cast(ISNULL([No Show Appts1] * 100,0) as decimal) / cast(([Count] * 100) as decimal),4) as decimal) >=.80\n",
    "\n",
    "\n",
    "\n",
    "select\n",
    "db1.[SCCA Contract]\n",
    ",db1.[Payor Class]\n",
    ",db1.[Payor Subclass]\n",
    ",dp1.[MRN Alpha]\n",
    ",dd1.Date\n",
    "\n",
    "into #prevbilling\n",
    "from oasis.mart.v_FactEncAll fe1 \n",
    "inner join oasis.mart.v_DimPayorBenPlan db1 on db1.[Payor Ben Plan Key] = fe1.[Payor Ben Plan Key]\n",
    "inner join oasis.mart.v_DimDate dd1 on dd1.[Date Key] = fe1.[Discharge Date Key]\n",
    "inner join oasis.mart.v_DimPatient dp1 on dp1.[Pat Key] = fe1.[Pat Key]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "select \n",
    "MRN 'MRN'\n",
    ",(select count(*)\n",
    "\n",
    "from #tempnoshow p\n",
    "where p.[MRN] = a.MRN and cast(p.[Appt Date Time] as date) = cast(a.[Appt Date Time] as date) ) 'totalapptstoday'\n",
    ",[Contact Serial Number] 'Contact Serial Number'\n",
    ",[Appt Date Time] 'Appt Date Time'\n",
    ",ISNULL([No Show Appts],0) 'No show'\n",
    ",[Sched Appt Length] as 'length'\n",
    ",(SELECT sum(1)\n",
    "from #tempnoshow b \n",
    "where a.[Pat Key] = b.[Pat Key] and a.[Date Key] >= b.[Date Key]\n",
    "group by b.[Pat Key]\n",
    ") as 'NumAppt'\n",
    ",COALESCE((SELECT sum(b.[No show Appts])\n",
    "from #tempnoshow b \n",
    "where a.[Pat Key] = b.[Pat Key] and a.[Date Key] > b.[Date Key]\n",
    "group by b.[Pat Key]\n",
    "),0) as 'NumAptNS'\n",
    ", case when datepart(dw,[Appt Date]) =2 then 1 else 0 end as 'ApptMon'\n",
    ", case when datepart(dw,[Appt Date]) =3 then 1 else 0 end as 'ApptTue'\n",
    ", case when datepart(dw,[Appt Date]) =4 then 1 else 0 end as 'ApptWed'\n",
    ", case when datepart(dw,[Appt Date]) =5 then 1 else 0 end as 'ApptThur'\n",
    ", case when datepart(dw,[Appt Date]) =6 then 1 else 0 end as 'ApptFri'\n",
    ", case when datepart(hh,[Appt Date Time]) between 4 and 11 then 1 else 0 end as 'AMappt'\n",
    ",ISNULL(LAG([No show Appts],1) OVER (partition by [Pat Key] ORDER BY [Date Key] asc),0) as 'prevnoshow'\n",
    ", case when a.[Age] between 18 and 35 then 1 else 0 end as 'Age18to35'\n",
    ", case when a.[Age] between 36 and 55 then 1 else 0 end as 'Age36to55'\n",
    ", case when a.[Age] between 56 and 75 then 1 else 0 end as 'Age56to75'\n",
    ", case when a.[Age] > 75 then 1 else 0 end as 'Age76'\n",
    ",case when abs(ISNULL([leadtime],0))= 0 then .1 else abs(ISNULL([leadtime],0)) end 'leadtime'\n",
    ",COALESCE(case when [TopPayor] is not null then [TopPayor] else\n",
    "(SELECT TOP 1 case when p.[SCCA Contract] like 'Premera%' and p.[Payor Class] not like 'Medi%' then 1 else 0 end\n",
    "from\n",
    "#prevbilling p\n",
    "where p.[MRN Alpha] = a.[MRN]\n",
    "and p.Date<a.[Appt Date]\n",
    "order by p.Date desc\n",
    ") end,0)\n",
    " as 'TopPayor'\n",
    ",COALESCE(case when [Next5Payors] is not null then [Next5Payors] else\n",
    "(SELECT TOP 1 case when p.[Payor Subclass] like 'Regence%' or \n",
    "p.[Payor Subclass] like 'United%' or \n",
    "p.[Payor Subclass] like 'BCBS%' or \n",
    "p.[Payor Subclass] like 'Aetna%' or \n",
    "p.[Payor Subclass] like 'BDCT%' and p.[Payor Class] not like 'Medi%' then 1 else 0 end\n",
    "from\n",
    "#prevbilling p\n",
    "where p.[MRN Alpha] = a.[MRN]\n",
    "and p.Date<a.[Appt Date]\n",
    "order by p.Date desc\n",
    ") end,0)\n",
    " as 'Next5Payors'\n",
    ", COALESCE(case when [medicaid] is not null then [Medicaid] else\n",
    "(SELECT TOP 1 case when p.[Payor Class] like 'Medicaid%' then 1 else 0 end \n",
    "from\n",
    "#prevbilling p\n",
    "where p.[MRN Alpha] = a.[MRN]\n",
    "and p.Date<a.[Appt Date]\n",
    "order by p.Date desc\n",
    ") end,0)\n",
    "as 'Medicaid'\n",
    ",COALESCE(case when [medicare] is not null then [Medicare] else\n",
    "(SELECT TOP 1 case when p.[Payor Class] is not null and p.[Payor Class] like 'Medicare%' then 1 else 0 end \n",
    "from\n",
    "#prevbilling p\n",
    "where p.[MRN Alpha] = a.[MRN]\n",
    "and p.Date<a.[Appt Date]\n",
    "order by p.Date desc\n",
    ") end,0) as 'Medicare' \n",
    ",COALESCE(case when [selfpay] is not null then [selfpay] else\n",
    "(SELECT TOP 1 case when p.[Payor Class] is not null and p.[Payor Class] like 'Self Pay' then 1 else 0 end \n",
    "from\n",
    "#prevbilling p\n",
    "where p.[MRN Alpha] = a.[MRN]\n",
    "and p.Date<a.[Appt Date]\n",
    "order by p.Date desc\n",
    ") end,0)\n",
    " as 'SelfPay'\n",
    ",ISNULL(case when ABS(ROUND(3959 * ACOS(\n",
    "SIN(RADIANS([PatLat])) * SIN(RADIANS([SiteLat])) +\n",
    "COS(RADIANS([PatLat])) * COS(RADIANS([SiteLat])) * COS(RADIANS([SiteLong]) - RADIANS([PatLong]))),1)) = 0 then .1 else \n",
    "ABS(ROUND(3959 * ACOS(\n",
    "SIN(RADIANS([PatLat])) * SIN(RADIANS([SiteLat])) +\n",
    "COS(RADIANS([PatLat])) * COS(RADIANS([SiteLat])) * COS(RADIANS([SiteLong]) - RADIANS([PatLong]))),1)) end ,.1)\n",
    "as 'DistanceMiLog'\n",
    ",africanamericanrace\n",
    ",americanindianrace\n",
    ",multirace\n",
    ",hispanicrace\n",
    ",otherrace\n",
    ",whiterace\n",
    ",pacislanderrace\n",
    ",ismale\n",
    ",asianrace\n",
    ",employed\n",
    ",nophonenumber\n",
    ",case when [Appt Type Class] = 'Procedure' then 1 else 0 end as 'procedureappt'\n",
    ",case when [Appt Type Class] = 'Radiation Oncology' then 1 else 0 end as 'radoncappt'\n",
    ",case when [Appt Type Class] = 'Physical Therapy' then 1 else 0 end as 'ptappt'\n",
    ",case when [Appt Type Class] = 'Infusion' then 1 else 0 end as 'infappt'\n",
    ", case when [Appt Type Class] = 'Clinic' then 1 else 0 end as 'clinicappt'\n",
    ",case when [Appt Type Class] = 'Interventional Radiology' then 1 else 0 end as 'intradappt'\n",
    ", case when [Appt Type Class] = 'Apheresis' then 1 else 0 end as 'apheresisappt'\n",
    ",case when [Appt Type Class] = 'Imaging' then 1 else 0 end as 'imagingappt'\n",
    " , case when [Prov Type Subcategory] = 'MA' then 1 else 0 end as 'maprov'\n",
    " , case when [Prov Type Subcategory] = 'Resident' then 1 else 0 end as 'residentprov'\n",
    "  , case when [Prov Type Subcategory] = 'Supportive Care' then 1 else 0 end as 'suppcareprov'\n",
    "   , case when [Prov Type Subcategory] = 'MD' then 1 else 0 end as 'mdprov'\n",
    "    , case when [Prov Type Subcategory] = 'APP/Fellow' then 1 else 0 end as 'appprov'\n",
    ",newappt\n",
    ",retappt\n",
    ",[Service Line]\n",
    ",[Appt Type Name]\n",
    ",[Prov Name]\n",
    ",isnull((SELECT count(*) from #tempnoshow abc\n",
    "where abc.[Appt Type Key] = A.[Appt Type Key] and ABC.MRN = A.MRN and A.[Appt Date Time] > ABC.[Appt Date Time]),0) 'PreviousApptsOfType'\n",
    ",isnull((SELECT sum(ISNULL(abc1.[No Show Appts],0))\n",
    "from #tempnoshow ABC1\n",
    "where ABC1.[Appt Type Key] = A.[Appt Type Key] and ABC1.MRN = A.MRN and A.[Appt Date Time] > ABC1.[Appt Date Time]),0) 'PreviousNSOfType'\n",
    "\n",
    "\n",
    "\n",
    ",coalesce(case when [Disease Type] not in ('Unmapped','No Value') then [Disease Type] \n",
    "when [Disease Type] in ('Unmapped','Value') and [Disease Subgroup] = 'Unmapped' then (select top 1 [Disease Type] from #diagnoses d where d.[MRN Alpha] = a.MRN and d.Date <= a.[Appt Date Time] order by d.date desc)\n",
    "else [Disease Subgroup] end,'No Prior Dx') 'Disease Type'\n",
    "\n",
    "into oasis_sandbox.cat.gbusch_NoShowFeatures\n",
    "from #tempnoshow a\n",
    "inner join #apptkeys ak on a.[Appt Type Key] = ak.[Appt Type Key] and ak.[Service Line Key] = a.[Service Line Key]\n",
    "where [Appt Date Time] between dateadd(day,-730,getdate()) and dateadd(day,14,GETDATE())\n",
    "\n",
    "and not ([Appt Date]<= getdate() and [No show Appts] is null)\n",
    "and  case when [Prov Type Subcategory] = 'Nurse' then 1 else 0 end = 0\n",
    "order by [Appt Date Time] desc\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as con:\n",
    "    con.execution_options(autocommit=True).execute(building_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Query the NoShowData table\n",
    "with engine.connect() as con:\n",
    "\n",
    "    data= pd.read_sql_query('select * from cat.gbusch_NoShowFeatures',con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Truncate the NoShowPredictions table\n",
    "truncate_query = sqlalchemy.text(\"TRUNCATE TABLE oasis_sandbox.dbo.NoShowPredictions\")\n",
    "with engine.connect() as con:\n",
    "    con.execution_options(autocommit=True).execute(truncate_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#One hot encode Appt Type, Provider, Disease Type; join back to original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "AT_df = data[['Contact Serial Number', 'Appt Type Name']]\n",
    "\n",
    "appttype_df = pd.get_dummies(AT_df['Appt Type Name'], prefix='apptType')\n",
    "AT_df = pd.merge(AT_df, appttype_df, left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "AT_df.drop('Appt Type Name', axis=1, inplace=True)\n",
    "\n",
    "AT_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DT_df = data[['Contact Serial Number', 'Disease Type']]\n",
    "\n",
    "diseasetype_df = pd.get_dummies(DT_df['Disease Type'], prefix='disease')\n",
    "DT_df = pd.merge(DT_df, diseasetype_df, left_index=True, right_index=True)\n",
    "\n",
    "DT_df.drop('Disease Type', axis=1, inplace=True)\n",
    "#DT_df.drop('disease_Unmapped', axis=1, inplace=True)\n",
    "#DT_df.drop('disease_No Value', axis=1, inplace=True)\n",
    "DT_df.head()\n",
    "print(DT_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prov_df = data[['Contact Serial Number', 'Prov Name']]\n",
    "\n",
    "provname_df = pd.get_dummies(prov_df['Prov Name'], prefix='prov')\n",
    "prov_df = pd.merge(prov_df, provname_df, left_index=True, right_index=True)\n",
    "\n",
    "prov_df.drop('prov_Unknown', axis=1, inplace=True)\n",
    "prov_df.drop('Prov Name', axis=1, inplace=True)\n",
    "\n",
    "prov_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_data = pd.merge(data, AT_df, how='inner', on='Contact Serial Number')\n",
    "#final_data = pd.merge(final_data, prov_df, how='inner', on='Contact Serial Number')\n",
    "final_data = pd.merge(final_data, DT_df, how='inner', on='Contact Serial Number')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datahistoric = final_data[final_data['Appt Date Time'] < str(dt.datetime.now())]\n",
    "datafuture = final_data[final_data['Appt Date Time'] >= str(dt.datetime.now())]\n",
    "dropfuture = ['MRN', 'Contact Serial Number', 'Appt Date Time','No show','Service Line','Disease Type','Appt Type Name','Prov Name']\n",
    "\n",
    "datafuture = datafuture.drop(dropfuture,axis=1)\n",
    "\n",
    "#datahistoric.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "# fill missing \"prevnoshow\" values with 0\n",
    "datahistoric['prevnoshow'].fillna(value=0, inplace=True)\n",
    "\n",
    "# drop fields not used in training/test\n",
    "drophistoric = ['MRN', 'Contact Serial Number', 'Appt Date Time','Service Line','Disease Type','Appt Type Name','Prov Name']\n",
    "datahistoric = datahistoric.drop(drophistoric,axis=1)\n",
    "\n",
    "\n",
    "# scale appropriately for later weighting of variables\n",
    "\n",
    "datahistoric['PreviousNSOfType'] = scaler.fit_transform(datahistoric['PreviousNSOfType'].values.reshape(-1,1))\n",
    "datahistoric['PreviousApptsOfType'] = scaler.fit_transform(datahistoric['PreviousApptsOfType'].values.reshape(-1,1))\n",
    "datahistoric['leadtime'] = scaler.fit_transform(datahistoric['leadtime'].values.reshape(-1,1))\n",
    "datahistoric['DistanceMiLog'] = scaler.fit_transform(datahistoric['DistanceMiLog'].values.reshape(-1,1))\n",
    "datahistoric['NumAppt'] = scaler.fit_transform(datahistoric['NumAppt'].values.reshape(-1,1))\n",
    "datahistoric['NumAptNS'] = scaler.fit_transform(datahistoric['NumAptNS'].values.reshape(-1,1))\n",
    "datahistoric['length'] = scaler.fit_transform(datahistoric['length'].values.reshape(-1,1))\n",
    "datahistoric['totalapptstoday'] = scaler.fit_transform(datahistoric['totalapptstoday'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# fill missing \"No show\" and  \"prevnoshow\" values with 0\n",
    "datafuture['prevnoshow'].fillna(value=0, inplace=True)\n",
    "\n",
    "# scale appropriately for later weighting of variables\n",
    "datafuture['PreviousNSOfType'] = scaler.fit_transform(datafuture['PreviousNSOfType'].values.reshape(-1,1))\n",
    "datafuture['PreviousApptsOfType'] = scaler.fit_transform(datafuture['PreviousApptsOfType'].values.reshape(-1,1))\n",
    "datafuture['leadtime'] = scaler.fit_transform(datafuture['leadtime'].values.reshape(-1,1))\n",
    "datafuture['DistanceMiLog'] = scaler.fit_transform(datafuture['DistanceMiLog'].values.reshape(-1,1))\n",
    "datafuture['NumAppt'] = scaler.fit_transform(datafuture['NumAppt'].values.reshape(-1,1))\n",
    "datafuture['NumAptNS'] = scaler.fit_transform(datafuture['NumAptNS'].values.reshape(-1,1))\n",
    "datafuture['length'] = scaler.fit_transform(datafuture['length'].values.reshape(-1,1))\n",
    "datafuture['totalapptstoday'] = scaler.fit_transform(datafuture['totalapptstoday'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split past data into test and train\n",
    "train_frac = .7\n",
    "split = int(train_frac * len(datahistoric))\n",
    "\n",
    "datatrain = datahistoric[:split]\n",
    "data_train_noshow = datatrain[datatrain['No show'] == 1]\n",
    "data_train_show = datatrain[datatrain['No show'] == 0]\n",
    "length = int(len(data_train_noshow)*1.6)\n",
    "data_train_show = data_train_show.sample(n=length,random_state=42)\n",
    "datatrain = pd.concat([data_train_noshow,data_train_show])\n",
    "datatrain = datatrain.sample(frac=1.0)\n",
    "\n",
    "y_train = datatrain['No show']\n",
    "X_train = datatrain.drop('No show', axis=1)\n",
    "\n",
    "datatest = datahistoric[split:]\n",
    "X_test = datatest.drop('No show', axis=1)\n",
    "y_test = datatest['No show']\n",
    "\n",
    "print(\"X_train dimensions: \", X_train.shape)\n",
    "print(\"y_train dimensions: \", y_train.shape)\n",
    "print(\"-\" * 30)\n",
    "print(\"X_test dimensions: \", X_test.shape)\n",
    "print(\"y_test dimensions: \", y_test.shape)\n",
    "\n",
    "#X_train.isnull().any()\n",
    "\n",
    "#X_feat.head()\n",
    "#y_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_values = f_classif(X_train,y_train)\n",
    "significant_count = 0\n",
    "significant_idx = []\n",
    "for i in range(f_values[0].shape[0]):\n",
    "    if f_values[1][i] <1e-3:\n",
    "        significant_count += 1\n",
    "        significant_idx.append(i)\n",
    "        \n",
    "significant_idx = np.array(significant_idx)\n",
    "print(\"Selected Features: \", list(significant_idx))\n",
    "print(\"There are {} significant features.\".format(significant_count))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trainRed = X_train[X_train.columns[list(significant_idx)]]\n",
    "#X_trainRed.head()\n",
    "X_testRed = X_test[X_test.columns[list(significant_idx)]]\n",
    "X_testRed.head()\n",
    "datafuture = datafuture[datafuture.columns[list(significant_idx)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Fit and execute the GBC model; append Prediction and Probability to production\n",
    "# Gradient Boosting\n",
    "gbc = GradientBoostingClassifier(warm_start=True,verbose=True)\n",
    "gbc.fit(X_train, y_train)\n",
    "print(\"GBC accuracy: \", gbc.score(X_test, y_test))\n",
    "\n",
    "datafuture['predns'] = gbc.predict(datafuture)\n",
    "datafuture['probns'] = np.round(gbc.predict_proba(datafuture.drop('predns',axis=1))[:,1],4)\n",
    "print(\"ROC accuracy: \", roc_auc_score(y_test,gbc.predict(X_test)))\n",
    "print(\"F1 SCore: \", f1_score(y_test,gbc.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datafuture.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"LR accuracy: \", lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Random Forest with cross validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfc = RandomForestClassifier()\n",
    "params = [{'n_estimators':[500,600,700],'max_features':[.1,.15,.2,.25,.3,.35],'bootstrap':[True],'warm_start':[True],'verbose':[True],'n_jobs':[8]}]\n",
    "crf = GridSearchCV(rfc,params,cv=3)\n",
    "crf.fit(X_train, y_train)\n",
    "print(crf.best_params_)\n",
    "\n",
    "\n",
    "print(\"RFC accuracy: \", crf.score(X_test, y_test))\n",
    "\n",
    "#datafuture['predns'] = crf.predict(datafuture)\n",
    "#datafuture['probns'] = np.round(crf.predict_proba(datafuture.drop('predns',axis=1))[:,1],4)\n",
    "print(\"ROC accuracy: \", roc_auc_score(y_test,crf.predict(X_test)))\n",
    "print(\"F1 SCore: \", f1_score(y_test,crf.predict(X_test)))\n",
    "joblib.dump(crf,'randomforestclassifier.pkl')\n",
    "#print(datafuture.shape)\n",
    "print(datafuture.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "print(\"RFC accuracy: \", rfc.score(X_test, y_test))\n",
    "\n",
    "#datafuture['predns'] = crf.predict(datafuture)\n",
    "#datafuture['probns'] = np.round(crf.predict_proba(datafuture.drop('predns',axis=1))[:,1],4)\n",
    "print(\"ROC accuracy: \", roc_auc_score(y_test,crf.predict(X_test)))\n",
    "print(\"F1 SCore: \", f1_score(y_test,crf.predict(X_test)))\n",
    "joblib.dump(crf,'randomforestclassifier.pkl')\n",
    "#print(datafuture.shape)\n",
    "print(datafuture.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "crf= joblib.load('randomforestclassifier.pkl')\n",
    "datafuture['predns'] = crf.predict(datafuture)\n",
    "datafuture['probns'] = np.round(crf.predict_proba(datafuture.drop('predns',axis=1))[:,1],4)\n",
    "print(\"ROC accuracy: \", roc_auc_score(y_test,crf.predict(X_test)))\n",
    "print(\"F1 SCore: \", f1_score(y_test,crf.predict(X_test)))\n",
    "joblib.dump(crf,'randomforestclassifier.pkl')\n",
    "#print(datafuture.shape)\n",
    "print(datafuture.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"RFC accuracy: \", crf.score(X_test, y_test))\n",
    "\n",
    "datafuture['predns'] = crf.predict(datafuture)\n",
    "datafuture['probns'] = np.round(crf.predict_proba(datafuture.drop('predns',axis=1))[:,1],4)\n",
    "print(\"ROC accuracy: \", roc_auc_score(y_test,crf.predict(X_test)))\n",
    "print(\"F1 SCore: \", f1_score(y_test,crf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AdaBoost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "abc.fit(X_train, y_train)\n",
    "print(\"ABC accuracy: \", abc.score(X_test, y_test))\n",
    "datafuture['predns'] = lr.predict(datafuture)\n",
    "datafuture['probns'] = np.round(lr.predict_proba(datafuture.drop('predns',axis=1))[:,1],4)\n",
    "#print(datafuture.shape)\n",
    "#print(datafuture.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Join the probability and prediction back to original data on index\n",
    "results_df = pd.merge(data,datafuture,\n",
    "                      left_index = True,\n",
    "                      right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Narrow down result set to 3 columns to be inserted into database\n",
    "results_df = results_df[['Contact Serial Number','predns','probns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Convert CSN from scientific notation to int\n",
    "results_df['Contact Serial Number'] = results_df['Contact Serial Number'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Building metadata table to prep table to be inserted into database, defines table values to be inserted into\n",
    "meta = MetaData()\n",
    "\n",
    "predictions = Table(\n",
    "    'NoShowPredictions', meta,\n",
    "    Column('ContactSerialNumber', Integer),\n",
    "    Column('PredictedOutcome', Integer),\n",
    "    Column('Probability', Float),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coef = lr.coef_ \n",
    "Xstd = (X_train.as_matrix(),0)\n",
    "print(Xstd*coef)\n",
    "print(X_train.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Connect to the database, insert CSN, Prediction, Probability into oasis_sandbox.dbo.NoShowPredictions\n",
    "\n",
    "engine = create_engine(\"(masked)OASIS_Sandbox?driver=SQL+Server+Native+Client+11.0?(masked)\")\n",
    "con= engine.connect() \n",
    "\n",
    "results_df = pd.DataFrame({'CSN':results_df['Contact Serial Number'].astype(str),'Pred':results_df['predns'].astype(str),'Probability':results_df['probns'].astype(str)})\n",
    "\n",
    "for csn, pred, prob in results_df.itertuples(index=False):\n",
    "     con.execute(predictions.insert().values(ContactSerialNumber=csn,PredictedOutcome=pred, Probability=prob))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
